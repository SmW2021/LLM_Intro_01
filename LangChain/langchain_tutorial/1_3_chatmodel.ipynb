{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatTongyi\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "chat = ChatTongyi()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 阻塞模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='勾股定理（Pythagorean Theorem）是几何学中一个非常重要的定理，尤其在**直角三角形**中应用广泛。\\n\\n---\\n\\n### ✅ **勾股定理的定义：**\\n\\n在**直角三角形**中，**斜边**（即对着直角的边，也就是最长的那条边）的平方等于另外两条**直角边**的平方和。\\n\\n---\\n\\n### 📐 数学表达式：\\n\\n如果一个直角三角形的两条直角边分别为 $ a $ 和 $ b $，斜边为 $ c $，那么有：\\n\\n$$\\na^2 + b^2 = c^2\\n$$\\n\\n---\\n\\n### 🔍 举例说明：\\n\\n比如一个直角三角形的两条直角边分别是 3 和 4，那么斜边 $ c $ 就是：\\n\\n$$\\nc = \\\\sqrt{3^2 + 4^2} = \\\\sqrt{9 + 16} = \\\\sqrt{25} = 5\\n$$\\n\\n所以这是一个“3-4-5”的直角三角形。\\n\\n---\\n\\n### 🧠 勾股数（Pythagorean Triples）：\\n\\n满足 $ a^2 + b^2 = c^2 $ 的正整数三元组称为**勾股数**。常见的有：\\n\\n- (3, 4, 5)\\n- (5, 12, 13)\\n- (6, 8, 10)\\n- (7, 24, 25)\\n\\n---\\n\\n### ⚙️ 应用场景：\\n\\n- 测量距离（如两点之间的直线距离）\\n- 计算高度、角度\\n- 在建筑、工程、计算机图形学等实际问题中广泛应用\\n\\n---\\n\\n### 📚 历史背景：\\n\\n这个定理以古希腊数学家**毕达哥拉斯**（Pythagoras）的名字命名，但他并不是第一个发现这个定理的人。早在公元前1800年的巴比伦泥板上就有相关记录，中国古代《周髀算经》中也有类似记载。\\n\\n---\\n\\n如果你需要我帮你解决具体的勾股定理问题，比如求某条边的长度、验证是否是直角三角形等等，也可以告诉我！', response_metadata={'model_name': 'qwen-turbo', 'finish_reason': 'stop', 'request_id': 'b61fd6aa-ff3f-97b6-87dc-eba48fa4fe84', 'token_usage': {'input_tokens': 26, 'output_tokens': 477, 'total_tokens': 503, 'prompt_tokens_details': {'cached_tokens': 0}}}, id='run-7244d42a-33b1-470b-9423-b0239c58b851-0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"你是一个数学专家\"),\n",
    "    HumanMessage(content=\"什么是勾股定理\"),\n",
    "]\n",
    "\n",
    "chat.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "勾股定理（Pythagorean Theorem）是几何学中一个非常重要的定理，它描述了直角三角形三边之间的关系。\n",
      "\n",
      "### 勾股定理的定义：\n",
      "\n",
      "在**直角三角形**中，**斜边**（即对着直角的边，也就是最长的那条边）的平方等于另外两条**直角边**（与直角相邻的两边）的平方和。\n",
      "\n",
      "---\n",
      "\n",
      "### 数学表达式：\n",
      "\n",
      "如果一个直角三角形的两条直角边分别为 $ a $ 和 $ b $，斜边为 $ c $，那么有：\n",
      "\n",
      "$$\n",
      "a^2 + b^2 = c^2\n",
      "$$\n",
      "\n",
      "---\n",
      "\n",
      "### 举例说明：\n",
      "\n",
      "比如一个直角三角形，两条直角边分别是 3 和 4，那么斜边 $ c $ 可以计算如下：\n",
      "\n",
      "$$\n",
      "c^2 = 3^2 + 4^2 = 9 + 16 = 25 \\Rightarrow c = \\sqrt{25} = 5\n",
      "$$\n",
      "\n",
      "所以这是一个“3-4-5”直角三角形。\n",
      "\n",
      "---\n",
      "\n",
      "### 历史背景：\n",
      "\n",
      "这个定理最早是由古希腊数学家**毕达哥拉斯**（Pythagoras）总结出来的，因此称为“勾股定理”。不过，早在毕达哥拉斯之前，古巴比伦人和古印度人就已经知道这个规律了。\n",
      "\n",
      "---\n",
      "\n",
      "### 应用：\n",
      "\n",
      "勾股定理广泛应用于：\n",
      "\n",
      "- 几何学（如计算距离、面积等）\n",
      "- 物理学（如矢量分解、运动分析）\n",
      "- 工程、建筑、导航等领域\n",
      "\n",
      "---\n",
      "\n",
      "如果你需要更深入的解释、证明方法或者应用实例，我也可以继续为你讲解！\n"
     ]
    }
   ],
   "source": [
    "print(chat.invoke(messages).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 流式模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "勾|股|定|理|（Pythagorean| Theorem）是|几何学中一个|非常重要的定理|，它描述了|直角三角形|三边之间的关系|。\n",
      "\n",
      "###| 勾股定理|的定义：\n",
      "\n",
      "在|**直角三角|形**中，|**斜边**|（即与直|角相对的边|，也就是最长的|边）的平方|等于另外两条**|直角边**|的平方和。\n",
      "\n",
      "|用公式表示为|：\n",
      "\n",
      "$$\n",
      "a|^2 + b|^2 = c|^2\n",
      "$$|\n",
      "\n",
      "其中：\n",
      "-| $ a $ 和| $ b $ 是|直角三角形|的两条直角|边；\n",
      "- $| c $ 是斜|边（即直|角对面的边|）。\n",
      "\n",
      "---\n",
      "\n",
      "###| 举例说明：\n",
      "\n",
      "|比如一个直角|三角形，两条|直角边分别是|3和4，|那么斜边就是|：\n",
      "\n",
      "$$\n",
      "c| = \\sqrt{|3^2 +| 4^2|} = \\sqrt|{9 + |16} =| \\sqrt{2|5} = |5\n",
      "$$\n",
      "\n",
      "|这就是著名的“3|-4-5|”直角三角|形。\n",
      "\n",
      "---\n",
      "\n",
      "###| 历史|背景：\n",
      "\n",
      "勾股|定理最早可以|追溯到古巴|比伦时期，|但最著名的记载|是出现在中国古代数学|著作《周髀|算经》中|，也被称为“|商高定理|”。在西方，|这个定理以|古希腊数学家|**毕达哥|拉斯**（Py|thagoras）的名字|命名，虽然他|可能并不是第一个发现|者。\n",
      "\n",
      "---\n",
      "\n",
      "###| 应用：\n",
      "\n",
      "|勾股定理|在很多领域都有|广泛应用，例如：\n",
      "\n",
      "|- 建|筑、工程、|导航、计算机图形|学、物理学等|；\n",
      "- 用于|计算两点之间的直线|距离（在坐标|系中）；\n",
      "|- 在三角函数|中也有重要应用|。\n",
      "\n",
      "---\n",
      "\n",
      "如果你需要|了解它的证明方法|、变体或|实际应用例子，|我也可以继续为你|讲解！||"
     ]
    }
   ],
   "source": [
    "for chunk in chat.stream(messages):\n",
    "    print(chunk.content, end=\"|\", flush=True)\n",
    "\n",
    "# flush=True\n",
    "# 每个chunk一生成就立即显示，而不是等到缓冲区满.对于流式对话，用户可以看到文字逐个出现的效果."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 缓存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_llm_cache\n",
    "from langchain.cache import InMemoryCache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "缓存的关键特性\n",
    "\n",
    "基于输入内容的哈希键：\n",
    " - 系统会对输入消息 \"说一个笑话\" 生成一个唯一的哈希键\n",
    " - 相同的输入总是生成相同的哈希键\n",
    " - 缓存只基于当前输入，不考虑对话历史"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.3 ms, sys: 4.63 ms, total: 30.9 ms\n",
      "Wall time: 3.47 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='当然可以！这是一个经典的笑话：\\n\\n有一天，小明去理发店剪头发。  \\n理发师问他：“要剪什么发型？”  \\n小明说：“我要像周杰伦那样！”  \\n理发师点点头，开始剪。  \\n剪完后，小明照镜子一看，惊讶地说：“这怎么像潘长江啊？！”  \\n理发师淡定地回答：“哦，那是我刚把你的发型‘微调’了一下。”  \\n\\n😄 你想要更多笑话吗？', response_metadata={'model_name': 'qwen-turbo', 'finish_reason': 'stop', 'request_id': '4553ac63-8398-95f2-92e2-78a66786b54e', 'token_usage': {'input_tokens': 15, 'output_tokens': 99, 'total_tokens': 114, 'prompt_tokens_details': {'cached_tokens': 0}}}, id='run-50b5074c-566e-4544-a385-3028ccf74ea8-0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "set_llm_cache(InMemoryCache())\n",
    "\n",
    "# The first time, it is not yet in cache, so it should take longer\n",
    "chat.invoke(\"说一个笑话\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 772 µs, sys: 68 µs, total: 840 µs\n",
      "Wall time: 828 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='当然可以！这是一个经典的笑话：\\n\\n有一天，小明去理发店剪头发。  \\n理发师问他：“要剪什么发型？”  \\n小明说：“我要像周杰伦那样！”  \\n理发师点点头，开始剪。  \\n剪完后，小明照镜子一看，惊讶地说：“这怎么像潘长江啊？！”  \\n理发师淡定地回答：“哦，那是我刚把你的发型‘微调’了一下。”  \\n\\n😄 你想要更多笑话吗？', response_metadata={'model_name': 'qwen-turbo', 'finish_reason': 'stop', 'request_id': '4553ac63-8398-95f2-92e2-78a66786b54e', 'token_usage': {'input_tokens': 15, 'output_tokens': 99, 'total_tokens': 114, 'prompt_tokens_details': {'cached_tokens': 0}}}, id='run-50b5074c-566e-4544-a385-3028ccf74ea8-0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# The second time it is, so it goes faster\n",
    "chat.invoke(\"说一个笑话\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自定义Chat model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, AsyncIterator, Dict, Iterator, List, Optional\n",
    "\n",
    "from langchain_core.callbacks import (\n",
    "    AsyncCallbackManagerForLLMRun,\n",
    "    CallbackManagerForLLMRun,\n",
    ")\n",
    "from langchain_core.language_models import BaseChatModel, SimpleChatModel\n",
    "from langchain_core.messages import AIMessageChunk, BaseMessage, HumanMessage\n",
    "from langchain_core.outputs import ChatGeneration, ChatGenerationChunk, ChatResult\n",
    "from langchain_core.runnables import run_in_executor\n",
    "\n",
    "\n",
    "class CustomChatModelAdvanced(BaseChatModel):\n",
    "    \"\"\"A custom chat model that echoes the first `n` characters of the input.\n",
    "\n",
    "    When contributing an implementation to LangChain, carefully document\n",
    "    the model including the initialization parameters, include\n",
    "    an example of how to initialize the model and include any relevant\n",
    "    links to the underlying models documentation or API.\n",
    "\n",
    "    Example:\n",
    "\n",
    "        .. code-block:: python\n",
    "\n",
    "            model = CustomChatModel(n=2)\n",
    "            result = model.invoke([HumanMessage(content=\"hello\")])\n",
    "            result = model.batch([[HumanMessage(content=\"hello\")],\n",
    "                                 [HumanMessage(content=\"world\")]])\n",
    "    \"\"\"\n",
    "\n",
    "    model_name: str\n",
    "    \"\"\"The name of the model\"\"\"\n",
    "    n: int\n",
    "    \"\"\"The number of characters from the last message of the prompt to be echoed.\"\"\"\n",
    "\n",
    "    def _generate(\n",
    "        self,\n",
    "        messages: List[BaseMessage],\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> ChatResult:\n",
    "        \"\"\"Override the _generate method to implement the chat model logic.\n",
    "\n",
    "        This can be a call to an API, a call to a local model, or any other\n",
    "        implementation that generates a response to the input prompt.\n",
    "\n",
    "        Args:\n",
    "            messages: the prompt composed of a list of messages.\n",
    "            stop: a list of strings on which the model should stop generating.\n",
    "                  If generation stops due to a stop token, the stop token itself\n",
    "                  SHOULD BE INCLUDED as part of the output. This is not enforced\n",
    "                  across models right now, but it's a good practice to follow since\n",
    "                  it makes it much easier to parse the output of the model\n",
    "                  downstream and understand why generation stopped.\n",
    "            run_manager: A run manager with callbacks for the LLM.\n",
    "        \"\"\"\n",
    "        # Replace this with actual logic to generate a response from a list\n",
    "        # of messages.\n",
    "        last_message = messages[-1]\n",
    "        tokens = last_message.content[: self.n]\n",
    "        message = AIMessage(\n",
    "            content=tokens,\n",
    "            additional_kwargs={},  # Used to add additional payload (e.g., function calling request)\n",
    "            response_metadata={  # Use for response metadata\n",
    "                \"time_in_seconds\": 3,\n",
    "            },\n",
    "        )\n",
    "        ##\n",
    "\n",
    "        generation = ChatGeneration(message=message)\n",
    "        return ChatResult(generations=[generation])\n",
    "\n",
    "    def _stream(\n",
    "        self,\n",
    "        messages: List[BaseMessage],\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> Iterator[ChatGenerationChunk]:\n",
    "        \"\"\"Stream the output of the model.\n",
    "\n",
    "        This method should be implemented if the model can generate output\n",
    "        in a streaming fashion. If the model does not support streaming,\n",
    "        do not implement it. In that case streaming requests will be automatically\n",
    "        handled by the _generate method.\n",
    "\n",
    "        Args:\n",
    "            messages: the prompt composed of a list of messages.\n",
    "            stop: a list of strings on which the model should stop generating.\n",
    "                  If generation stops due to a stop token, the stop token itself\n",
    "                  SHOULD BE INCLUDED as part of the output. This is not enforced\n",
    "                  across models right now, but it's a good practice to follow since\n",
    "                  it makes it much easier to parse the output of the model\n",
    "                  downstream and understand why generation stopped.\n",
    "            run_manager: A run manager with callbacks for the LLM.\n",
    "        \"\"\"\n",
    "        last_message = messages[-1]\n",
    "        tokens = last_message.content[: self.n]\n",
    "\n",
    "        for token in tokens:\n",
    "            chunk = ChatGenerationChunk(message=AIMessageChunk(content=token))\n",
    "\n",
    "            if run_manager:\n",
    "                # This is optional in newer versions of LangChain\n",
    "                # The on_llm_new_token will be called automatically\n",
    "                run_manager.on_llm_new_token(token, chunk=chunk)\n",
    "\n",
    "            yield chunk\n",
    "\n",
    "        # Let's add some other information (e.g., response metadata)\n",
    "        chunk = ChatGenerationChunk(\n",
    "            message=AIMessageChunk(content=\"\", response_metadata={\"time_in_sec\": 3})\n",
    "        )\n",
    "        if run_manager:\n",
    "            # This is optional in newer versions of LangChain\n",
    "            # The on_llm_new_token will be called automatically\n",
    "            run_manager.on_llm_new_token(token, chunk=chunk)\n",
    "        yield chunk\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        \"\"\"Get the type of language model used by this chat model.\"\"\"\n",
    "        return \"echoing-chat-model-advanced\"\n",
    "\n",
    "    @property\n",
    "    def _identifying_params(self) -> Dict[str, Any]:\n",
    "        \"\"\"Return a dictionary of identifying parameters.\n",
    "\n",
    "        This information is used by the LangChain callback system, which\n",
    "        is used for tracing purposes make it possible to monitor LLMs.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            # The model name allows users to specify custom token counting\n",
    "            # rules in LLM monitoring applications (e.g., in LangSmith users\n",
    "            # can provide per token pricing for their model and monitor\n",
    "            # costs for the given LLM.)\n",
    "            \"model_name\": self.model_name,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Meo', response_metadata={'time_in_seconds': 3}, id='run-d80e099b-8d3c-470e-b3e7-0de8f24af079-0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    BaseMessage,\n",
    "    FunctionMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    "    ToolMessage,\n",
    ")\n",
    "\n",
    "model = CustomChatModelAdvanced(n=3, model_name=\"my_custom_model\")\n",
    "\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"hello!\"),\n",
    "        AIMessage(content=\"Hi there human!\"),\n",
    "        HumanMessage(content=\"Meow!\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c|a|t||"
     ]
    }
   ],
   "source": [
    "# 输入也支持字符串，可以等同于`[HumanMessage(content=\"cat vs dog\")]`\n",
    "for chunk in model.stream(\"cat vs dog\"):\n",
    "    print(chunk.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 记录消耗tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 388\n",
      "\tPrompt Tokens: 26\n",
      "\tCompletion Tokens: 362\n",
      "Successful Requests: 1\n",
      "Total Cost (CYN): ¥0.007448\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from callbacks.manager import get_generic_llms_callback\n",
    "\n",
    "messages = [\n",
    "        SystemMessage(content=\"你是一个数学专家\"),\n",
    "        HumanMessage(content=\"什么是勾股定理\"),\n",
    "    ]\n",
    "\n",
    "with get_generic_llms_callback() as cb:\n",
    "    chat.invoke(messages)\n",
    "    print(cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "勾|股|定|理|（Pythagorean| Theorem）是|几何学中一个|非常重要的定理|，尤其在**|直角三角形|**中应用广泛|。\n",
      "\n",
      "---\n",
      "\n",
      "###| ✅ 勾|股定理的|定义：\n",
      "\n",
      "> 在|**直角三角|形**中，|**斜边**|（即与直|角相对的边|，也就是最长的|边）的平方|等于**两条直|角边**（|即构成直角|的两边）的|平方和。\n",
      "\n",
      "---\n",
      "\n",
      "|### 📐| 数学表达式|：\n",
      "\n",
      "如果一个直|角三角形的|两条直角边|分别为 $ a $| 和 $ b $|，斜边为| $ c $，|那么有：\n",
      "\n",
      "$$|\n",
      "a^2| + b^2| = c^2|\n",
      "$$\n",
      "\n",
      "---\n",
      "\n",
      "|### 🔍 |举例说明：\n",
      "\n",
      "比如|一个直角三角|形，两条直|角边分别是 |3 和 4|，那么斜边| $ c $ 是|多少？\n",
      "\n",
      "$$\n",
      "|c = \\sqrt|{3^2| + 4^|2} = \\|sqrt{9 +| 16}| = \\sqrt{|25} =| 5\n",
      "$$|\n",
      "\n",
      "这就是著名的 **|3-4-|5 直角|三角形**。\n",
      "\n",
      "|---\n",
      "\n",
      "###| 🧠 历|史背景：\n",
      "\n",
      "这个|定理以古|希腊数学家**|毕达哥拉斯|**（Pythag|oras）的名字命名|，但他并不是第一个|发现这个定理|的人。早在公元前|1800|年的巴比伦|时期，人们就已经|知道这个关系。|不过，毕达|哥拉斯及其学|派对这个定|理进行了系统的证明|和推广。\n",
      "\n",
      "---\n",
      "\n",
      "|### ⚠|️ 注意事项：\n",
      "\n",
      "|- 勾|股定理只|适用于**直角|三角形**。\n",
      "|- 如果已知|任意两边，可以|求出第三边|。\n",
      "- 它|是**欧几|里得几何**|中的基本定理|之一。\n",
      "\n",
      "---\n",
      "\n",
      "###| 📘 应|用领域：\n",
      "\n",
      "-| 建筑|、工程、导航|、计算机图形学|、物理学等。\n",
      "|- 用于计算|距离、角度、|面积等。\n",
      "\n",
      "---\n",
      "\n",
      "|如果你需要我用|中文解释、举例|或推导勾|股定理，|欢迎继续提问！||\n",
      "Tokens Used: 458\n",
      "\tPrompt Tokens: 26\n",
      "\tCompletion Tokens: 432\n",
      "Successful Requests: 1\n",
      "Total Cost (CYN): ¥0.008848\n"
     ]
    }
   ],
   "source": [
    "from tongyi.chat_model import CustomChatTongyi\n",
    "\n",
    "# dashscope_api_key作为参数传入\n",
    "# 或者配置环境变量`DASHSCOPE_API_KEY`\n",
    "chat = CustomChatTongyi()\n",
    "\n",
    "with get_generic_llms_callback() as cb:\n",
    "    for chunk in chat.stream(messages):\n",
    "        print(chunk.content, end=\"|\", flush=True)\n",
    "    \n",
    "    print()\n",
    "    print(cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
