{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatTongyi\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "chat = ChatTongyi()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PydanticOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup='ä¸ºä»€ä¹ˆæ•°å­¦ä¹¦æ€»æ˜¯å¾ˆå¿§éƒï¼Ÿ', punchline='å› ä¸ºå®ƒæœ‰å¤ªå¤šçš„é—®é¢˜ã€‚')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "\n",
    "\n",
    "# Define your desired data structure.\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"å¼€å¯ä¸€ä¸ªç¬‘è¯çš„é—®é¢˜\")\n",
    "    punchline: str = Field(description=\"è§£ç­”ç¬‘è¯çš„ç­”æ¡ˆ\")\n",
    "\n",
    "    # You can add custom validation logic easily with Pydantic.\n",
    "    @validator(\"setup\")\n",
    "    def question_ends_with_question_mark(cls, field):\n",
    "        if field[-1] != \"ï¼Ÿ\":\n",
    "            raise ValueError(\"Badly formed question!\")\n",
    "        return field\n",
    "\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = PydanticOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"æ ¹æ®ç”¨æˆ·çš„è¾“å…¥è¿›è¡Œè§£ç­”.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "# And a query intended to prompt a language model to populate the data structure.\n",
    "chain = prompt | chat | parser\n",
    "chain.invoke({\"query\": \"è®²ä¸€ä¸ªç¬‘è¯\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"setup\": {\"title\": \"Setup\", \"description\": \"\\\\u5f00\\\\u542f\\\\u4e00\\\\u4e2a\\\\u7b11\\\\u8bdd\\\\u7684\\\\u95ee\\\\u9898\", \"type\": \"string\"}, \"punchline\": {\"title\": \"Punchline\", \"description\": \"\\\\u89e3\\\\u7b54\\\\u7b11\\\\u8bdd\\\\u7684\\\\u7b54\\\\u6848\", \"type\": \"string\"}}, \"required\": [\"setup\", \"punchline\"]}\\n```'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.Joke'>\n",
      "ä¸ºä»€ä¹ˆå¥¹åƒä¸èƒ–ï¼Ÿ\n",
      "å› ä¸ºå¥¹æ˜¯'ç˜¦'äººã€‚\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | chat | parser\n",
    "joke = chain.invoke({\"query\": \"ä¸ºä»€ä¹ˆå¥¹åƒä¸èƒ–ï¼Ÿ\"})  # ç›´æ¥å¾—åˆ°Jokeå¯¹è±¡\n",
    "\n",
    "print(type(joke))  # <class '__main__.Joke'>\n",
    "print(joke.setup)   # ç›´æ¥è®¿é—®å±æ€§\n",
    "print(joke.punchline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessageå†…å®¹: {\n",
      "  \"setup\": \"ä¸ºä»€ä¹ˆå¥¹åƒä¸èƒ–ï¼Ÿ\",\n",
      "  \"punchline\": \"å› ä¸ºå¥¹åƒçš„éƒ½æ˜¯'èƒ–'å­—ã€‚\"\n",
      "}\n",
      "è§£ææˆåŠŸ: setup='ä¸ºä»€ä¹ˆå¥¹åƒä¸èƒ–ï¼Ÿ' punchline=\"å› ä¸ºå¥¹åƒçš„éƒ½æ˜¯'èƒ–'å­—ã€‚\"\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "partial_chain = prompt | chat\n",
    "llm_response = partial_chain.invoke({\"query\": \"ä¸ºä»€ä¹ˆå¥¹åƒä¸èƒ–ï¼Ÿ\"})\n",
    "\n",
    "# æ£€æŸ¥å“åº”ç±»å‹å¹¶ç›¸åº”å¤„ç†\n",
    "if isinstance(llm_response, AIMessage):\n",
    "    raw_text = llm_response.content\n",
    "    print(\"AIMessageå†…å®¹:\", raw_text)\n",
    "    \n",
    "    try:\n",
    "        joke = parser.parse(raw_text)\n",
    "        print(\"è§£ææˆåŠŸ:\", joke)\n",
    "    except Exception as e:\n",
    "        print(\"è§£æå¤±è´¥:\", e)\n",
    "        print(\"åŸå§‹å†…å®¹:\", raw_text)\n",
    "else:\n",
    "    print(\"æœªçŸ¥å“åº”ç±»å‹:\", type(llm_response))\n",
    "    print(\"å“åº”å†…å®¹:\", llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup='ä¸ºä»€ä¹ˆå¥¹åƒä¸èƒ–ï¼Ÿ', punchline='å› ä¸ºå¥¹åƒçš„æ˜¯ç©ºæ°”ã€‚')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joke"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jsonè§£æå™¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': 'ä¸ºä»€ä¹ˆæ•°å­¦ä¹¦æ€»æ˜¯å¾ˆå¿§éƒï¼Ÿ', 'punchline': 'å› ä¸ºå®ƒæœ‰å¤ªå¤šçš„é—®é¢˜ã€‚'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = JsonOutputParser(pydantic_object=Joke)\n",
    "\n",
    "chain = prompt | chat | parser\n",
    "\n",
    "chain.invoke({\"query\": \"è®²ä¸€ä¸ªç¬‘è¯\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"setup\": {\"title\": \"Setup\", \"description\": \"\\\\u5f00\\\\u542f\\\\u4e00\\\\u4e2a\\\\u7b11\\\\u8bdd\\\\u7684\\\\u95ee\\\\u9898\", \"type\": \"string\"}, \"punchline\": {\"title\": \"Punchline\", \"description\": \"\\\\u89e3\\\\u7b54\\\\u7b11\\\\u8bdd\\\\u7684\\\\u7b54\\\\u6848\", \"type\": \"string\"}}, \"required\": [\"setup\", \"punchline\"]}\\n```'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# è‡ªå®šä¹‰è§£æå™¨\n",
    "## Runnable Lambdas and Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hELLO! hOW CAN i ASSIST YOU TODAY? ğŸ˜Š'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Iterable\n",
    "\n",
    "from langchain_core.messages import AIMessage, AIMessageChunk\n",
    "\n",
    "def parse(ai_message: AIMessage) -> str:\n",
    "    \"\"\"Parse the AI message.\"\"\"\n",
    "    return ai_message.content.swapcase()\n",
    "\n",
    "\n",
    "chain = chat | parse\n",
    "chain.invoke(\"hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runnable Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i| AM| q|WEN|, A LARGE-SCALE| LANGUAGE MODEL DEVELOPED BY| aLIBABA gROUP.||"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableGenerator\n",
    "\n",
    "\n",
    "def streaming_parse(chunks: Iterable[AIMessageChunk]) -> Iterable[str]:\n",
    "    for chunk in chunks:\n",
    "        yield chunk.content.swapcase()\n",
    "\n",
    "# å¯¹äºstreaming func, LangChainæ— æ³•è‡ªåŠ¨è¯†åˆ«è¿™æ˜¯æµå¼å¤„ç†å‡½æ•°\n",
    "# éœ€è¦æ˜ç¡®å‘Šè¯‰å®ƒæ˜¯Runnable\n",
    "streaming_parse = RunnableGenerator(streaming_parse)\n",
    "\n",
    "chain = chat | streaming_parse\n",
    "\n",
    "for chunk in chain.stream(\"tell me about yourself in one sentence\"):\n",
    "    print(chunk, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(ai_message: AIMessage) -> str:\n",
    "    return ai_message.content.swapcase()\n",
    "\n",
    "chain = chat | parse\n",
    "result = chain.invoke(\"hello\")  # ç­‰å¾…å®Œæ•´å“åº”ï¼Œç„¶åä¸€æ¬¡æ€§å¤„ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hELLO! hOW CAN i ASSIST YOU TODAY? ğŸ˜Š'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i|'M| AN| ai| ASSISTANT DESIGNED TO HELP| WITH INFORMATION, ANSWER| QUESTIONS, AND ENGAGE| IN CONVERSATIONS.||"
     ]
    }
   ],
   "source": [
    "def streaming_parse(chunks: Iterable[AIMessageChunk]) -> Iterable[str]:\n",
    "    for chunk in chunks:\n",
    "        yield chunk.content.swapcase()  # é€ä¸ªå®æ—¶å¤„ç†\n",
    "\n",
    "chain = chat | RunnableGenerator(streaming_parse)\n",
    "# å®æ—¶å¤„ç†ï¼Œæ— éœ€ç­‰å¾…å®Œæ•´å“åº”\n",
    "for chunk in chain.stream(\"tell me about yourself in one sentence\"):\n",
    "    print(chunk, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¤„ç†: I|å¤„ç†: 'M|å¤„ç†: ğŸ”¹AN|å¤„ç†: ğŸ”¹AI|å¤„ç†: ğŸ”¹ASSISTANTğŸ”¹DESIGNEDğŸ”¹TOğŸ”¹HELP|å¤„ç†: ğŸ”¹WITHğŸ”¹INFORMATION,ğŸ”¹ANSWER|å¤„ç†: ğŸ”¹QUESTIONS,ğŸ”¹ANDğŸ”¹PROVIDE|å¤„ç†: ğŸ”¹SUPPORTğŸ”¹INğŸ”¹AğŸ”¹WIDE|å¤„ç†: ğŸ”¹RANGEğŸ”¹OFğŸ”¹TOPICS.|å¤„ç†: |"
     ]
    }
   ],
   "source": [
    "def step1(chunks: Iterable[AIMessageChunk]) -> Iterable[str]:\n",
    "    for chunk in chunks:\n",
    "        yield chunk.content.upper()\n",
    "\n",
    "def step2(chunks: Iterable[str]) -> Iterable[str]:\n",
    "    for chunk in chunks:\n",
    "        yield chunk.replace(\" \", \"ğŸ”¹\")\n",
    "\n",
    "def step3(chunks: Iterable[str]) -> Iterable[str]:\n",
    "    for chunk in chunks:\n",
    "        yield f\"å¤„ç†: {chunk}\"\n",
    "\n",
    "# åˆ›å»ºæµå¼é“¾\n",
    "chain = (\n",
    "    chat \n",
    "    | RunnableGenerator(step1) \n",
    "    | RunnableGenerator(step2)\n",
    "    | RunnableGenerator(step3)\n",
    ")\n",
    "\n",
    "for chunk in chain.stream(\"tell me about yourself in one sentence\"):\n",
    "    print(chunk, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç»§æ‰¿è§£æå™¨åŸºç±»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.exceptions import OutputParserException\n",
    "from langchain_core.output_parsers import BaseOutputParser\n",
    "\n",
    "\n",
    "# The [bool] desribes a parameterization of a generic.\n",
    "# It's basically indicating what the return type of parse is\n",
    "# in this case the return type is either True or False\n",
    "class BooleanOutputParser(BaseOutputParser[bool]):\n",
    "    \"\"\"Custom boolean parser.\"\"\"\n",
    "\n",
    "    true_val: str = \"YES\"\n",
    "    false_val: str = \"NO\"\n",
    "\n",
    "    def parse(self, text: str) -> bool:\n",
    "        cleaned_text = text.strip().upper()\n",
    "        if cleaned_text not in (self.true_val.upper(), self.false_val.upper()):\n",
    "            raise OutputParserException(\n",
    "                f\"BooleanOutputParser expected output value to either be \"\n",
    "                f\"{self.true_val} or {self.false_val} (case-insensitive). \"\n",
    "                f\"Received {cleaned_text}.\"\n",
    "            )\n",
    "        return cleaned_text == self.true_val.upper()\n",
    "\n",
    "    @property\n",
    "    def _type(self) -> str:\n",
    "        return \"boolean_output_parser\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = BooleanOutputParser()\n",
    "chain = chat | parser\n",
    "chain.invoke('å›ç­”æˆ‘çš„é—®é¢˜ï¼Œå¦‚æœç­”æ¡ˆæ˜¯\"æ˜¯\"ï¼Œç›´æ¥å›ç­”\"Yes\"ï¼Œå¦‚æœç­”æ¡ˆæ˜¯å¦ï¼Œç›´æ¥å›ç­”\"No\"ã€‚æˆ‘çš„é—®é¢˜æ˜¯ï¼š\"ä¸€å‘¨æœ‰7å¤©å—\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# åˆ›å»ºæç¤ºè¯ï¼Œè¦æ±‚LLMè¾“å‡ºYES/NO\n",
    "prompt = PromptTemplate(\n",
    "    template=\"å›ç­”ä»¥ä¸‹é—®é¢˜ï¼Œåªè¾“å‡ºYESæˆ–NO:\\n{question}\",\n",
    "    input_variables=[\"question\"]\n",
    ")\n",
    "\n",
    "# åˆ›å»ºå¤„ç†é“¾\n",
    "chain = prompt | chat | BooleanOutputParser()\n",
    "\n",
    "# è°ƒç”¨\n",
    "result = chain.invoke({\"question\": \"å¤©ç©ºæ˜¯è“è‰²çš„å—ï¼Ÿ\"})\n",
    "print(result)  # True æˆ– False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutputParserException",
     "evalue": "BooleanOutputParser expected output value to either be æ˜¯ or å¦ (case-insensitive). Received YES.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m chinese_parser \u001b[38;5;241m=\u001b[39m BooleanOutputParser(true_val\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mæ˜¯\u001b[39m\u001b[38;5;124m\"\u001b[39m, false_val\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124må¦\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m chain \u001b[38;5;241m=\u001b[39m prompt \u001b[38;5;241m|\u001b[39m chat \u001b[38;5;241m|\u001b[39m chinese_parser\n\u001b[0;32m----> 5\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mä½ å–œæ¬¢Pythonå—ï¼Ÿ\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.10/site-packages/langchain_core/runnables/base.py:2499\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   2497\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2498\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[0;32m-> 2499\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2500\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2501\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# mark each step as a child run\u001b[39;49;00m\n\u001b[1;32m   2502\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2503\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseq:step:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2504\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2505\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2506\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   2507\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.10/site-packages/langchain_core/output_parsers/base.py:169\u001b[0m, in \u001b[0;36mBaseOutputParser.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Union[\u001b[38;5;28mstr\u001b[39m, BaseMessage], config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    167\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, BaseMessage):\n\u001b[0;32m--> 169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[1;32m    179\u001b[0m             \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_result([Generation(text\u001b[38;5;241m=\u001b[39minner_input)]),\n\u001b[1;32m    180\u001b[0m             \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    181\u001b[0m             config,\n\u001b[1;32m    182\u001b[0m             run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    183\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.10/site-packages/langchain_core/runnables/base.py:1626\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1622\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[1;32m   1623\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(var_child_runnable_config\u001b[38;5;241m.\u001b[39mset, child_config)\n\u001b[1;32m   1624\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m   1625\u001b[0m         Output,\n\u001b[0;32m-> 1626\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1627\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1628\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1629\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1630\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1631\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1632\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1633\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1634\u001b[0m     )\n\u001b[1;32m   1635\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1636\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.10/site-packages/langchain_core/runnables/config.py:347\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    346\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.10/site-packages/langchain_core/output_parsers/base.py:170\u001b[0m, in \u001b[0;36mBaseOutputParser.invoke.<locals>.<lambda>\u001b[0;34m(inner_input)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Union[\u001b[38;5;28mstr\u001b[39m, BaseMessage], config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    167\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, BaseMessage):\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[0;32m--> 170\u001b[0m             \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    173\u001b[0m             \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    174\u001b[0m             config,\n\u001b[1;32m    175\u001b[0m             run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    176\u001b[0m         )\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[1;32m    179\u001b[0m             \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_result([Generation(text\u001b[38;5;241m=\u001b[39minner_input)]),\n\u001b[1;32m    180\u001b[0m             \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    181\u001b[0m             config,\n\u001b[1;32m    182\u001b[0m             run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    183\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.10/site-packages/langchain_core/output_parsers/base.py:221\u001b[0m, in \u001b[0;36mBaseOutputParser.parse_result\u001b[0;34m(self, result, partial)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_result\u001b[39m(\u001b[38;5;28mself\u001b[39m, result: List[Generation], \u001b[38;5;241m*\u001b[39m, partial: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    209\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Parse a list of candidate model Generations into a specific format.\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \n\u001b[1;32m    211\u001b[0m \u001b[38;5;124;03m    The return value is parsed from only the first Generation in the result, which\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;124;03m        Structured output.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 221\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[26], line 17\u001b[0m, in \u001b[0;36mBooleanOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     15\u001b[0m cleaned_text \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mupper()\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cleaned_text \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrue_val\u001b[38;5;241m.\u001b[39mupper(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfalse_val\u001b[38;5;241m.\u001b[39mupper()):\n\u001b[0;32m---> 17\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBooleanOutputParser expected output value to either be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrue_val\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfalse_val\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (case-insensitive). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcleaned_text\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     21\u001b[0m     )\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cleaned_text \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrue_val\u001b[38;5;241m.\u001b[39mupper()\n",
      "\u001b[0;31mOutputParserException\u001b[0m: BooleanOutputParser expected output value to either be æ˜¯ or å¦ (case-insensitive). Received YES."
     ]
    }
   ],
   "source": [
    "# ä½¿ç”¨ä¸­æ–‡å“åº”\n",
    "chinese_parser = BooleanOutputParser(true_val=\"æ˜¯\", false_val=\"å¦\")\n",
    "\n",
    "chain = prompt | chat | chinese_parser\n",
    "result = chain.invoke({\"question\": \"ä½ å–œæ¬¢Pythonå—ï¼Ÿ\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# æ˜ç¡®è¦æ±‚ä¸­æ–‡è¾“å‡º\n",
    "prompt = PromptTemplate(\n",
    "    template=\"è¯·ç”¨ä¸­æ–‡å›ç­”ä»¥ä¸‹é—®é¢˜ï¼Œåªè¾“å‡º'æ˜¯'æˆ–'å¦'ï¼Œä¸è¦å…¶ä»–å†…å®¹:\\n{question}\",\n",
    "    input_variables=[\"question\"]\n",
    ")\n",
    "\n",
    "chinese_parser = BooleanOutputParser(true_val=\"æ˜¯\", false_val=\"å¦\")\n",
    "\n",
    "chain = prompt | chat | chinese_parser\n",
    "result = chain.invoke({\"question\": \"ä½ å–œæ¬¢Pythonå—ï¼Ÿ\"})\n",
    "print(result)  # True æˆ– False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## è§£æåŸå§‹çš„LLMè¾“å‡º\n",
    "æ¨¡å‹çš„è¾“å‡ºå…¶å®ç»å¸¸åŒ…å«ä¸€äº›é¢å¤–ä¿¡æ¯`metadata`çš„ï¼Œå› æ­¤å¦‚æœè§£æå™¨éœ€è¦è¿™éƒ¨åˆ†ä¿¡æ¯çš„è¯ï¼Œå¯ä»¥ä½¿ç”¨ä¸‹é¢çš„æ–¹æ³•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain_core.exceptions import OutputParserException\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.output_parsers import BaseGenerationOutputParser\n",
    "from langchain_core.outputs import ChatGeneration, Generation\n",
    "\n",
    "\n",
    "class StrInvertCase(BaseGenerationOutputParser[str]):\n",
    "    \"\"\"An example parser that inverts the case of the characters in the message.\n",
    "\n",
    "    This is an example parse shown just for demonstration purposes and to keep\n",
    "    the example as simple as possible.\n",
    "    \"\"\"\n",
    "\n",
    "    def parse_result(self, result: List[Generation], *, partial: bool = False) -> str:\n",
    "        \"\"\"Parse a list of model Generations into a specific format.\n",
    "\n",
    "        Args:\n",
    "            result: A list of Generations to be parsed. The Generations are assumed\n",
    "                to be different candidate outputs for a single model input.\n",
    "                Many parsers assume that only a single generation is passed it in.\n",
    "                We will assert for that\n",
    "            partial: Whether to allow partial results. This is used for parsers\n",
    "                     that support streaming\n",
    "        \"\"\"\n",
    "        if len(result) != 1:\n",
    "            raise NotImplementedError(\n",
    "                \"This output parser can only be used with a single generation.\"\n",
    "            )\n",
    "        generation = result[0]\n",
    "        if not isinstance(generation, ChatGeneration):\n",
    "            # Say that this one only works with chat generations\n",
    "            raise OutputParserException(\n",
    "                \"This output parser can only be used with a chat generation.\"\n",
    "            )\n",
    "        return generation.message.content.swapcase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yES'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = chat | StrInvertCase()\n",
    "chain.invoke('å›ç­”æˆ‘çš„é—®é¢˜ï¼Œå¦‚æœç­”æ¡ˆæ˜¯\"æ˜¯\"ï¼Œç›´æ¥å›ç­”\"Yes\"ï¼Œå¦‚æœç­”æ¡ˆæ˜¯å¦ï¼Œç›´æ¥å›ç­”\"No\"ã€‚æˆ‘çš„é—®é¢˜æ˜¯ï¼š\"ä¸€å‘¨æœ‰7å¤©å—\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç±»å‘½åå®ä½“è¯†åˆ«ï¼ˆNERï¼‰æŠ€æœ¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup='ä¸ºä»€ä¹ˆæ•°å­¦ä¹¦æ€»æ˜¯å¾ˆå¿§éƒï¼Ÿ', punchline='å› ä¸ºå®ƒæœ‰å¤ªå¤šçš„é—®é¢˜ã€‚')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define your desired data structure.\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"å¼€å¯ä¸€ä¸ªç¬‘è¯çš„é—®é¢˜\")\n",
    "    punchline: str = Field(description=\"è§£ç­”ç¬‘è¯çš„ç­”æ¡ˆ\")\n",
    "\n",
    "    # You can add custom validation logic easily with Pydantic.\n",
    "    @validator(\"setup\")\n",
    "    # def question_ends_with_question_mark(cls, field):\n",
    "    def test(cls, field):\n",
    "        if field[-1] != \"ï¼Ÿ\":\n",
    "            raise ValueError(\"Badly formed question!\")\n",
    "        return field\n",
    "\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = PydanticOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"æ ¹æ®ç”¨æˆ·çš„è¾“å…¥è¿›è¡Œè§£ç­”.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "# And a query intended to prompt a language model to populate the data structure.\n",
    "prompt_and_model = prompt | chat\n",
    "output = prompt_and_model.invoke({\"query\": \"è®²ä¸€ä¸ªç¬‘è¯\"})\n",
    "parser.invoke(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "# from langchain_openai import ChatOpenAI\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "print(format_instructions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
